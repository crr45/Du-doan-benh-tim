import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

# Äá»c dá»¯ liá»‡u
data = pd.read_csv('/content/drive/MyDrive/BaÌ€i taÌ£Ì‚p loÌ›Ìn nhoÌm 6/Colab Notebooks/heart-disease.csv')

# TÃ¡ch dá»¯ liá»‡u Ä‘áº§u vÃ o vÃ  Ä‘áº§u ra
X = data.drop(columns='target', axis=1)
Y = data['target']

# Chuáº©n hÃ³a dá»¯ liá»‡u
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# TÃ¡ch dá»¯ liá»‡u thÃ nh táº­p huáº¥n luyá»‡n vÃ  kiá»ƒm tra
X_train, X_test, Y_train, Y_test = train_test_split(X_scaled, Y, test_size=0.2, random_state=42)

# XÃ¢y dá»±ng mÃ´ hÃ¬nh máº¡ng neuron
model = Sequential([
    Dense(16, activation='relu', input_shape=(X_train.shape[1],)),
    Dense(8, activation='relu'),
    Dense(1, activation='sigmoid')
])

# BiÃªn dá»‹ch mÃ´ hÃ¬nh
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Huáº¥n luyá»‡n mÃ´ hÃ¬nh
model.fit(X_train, Y_train, epochs=100, batch_size=16, verbose=1)

# ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh
loss, accuracy = model.evaluate(X_test, Y_test)
print(f'âœ… Äá»™ chÃ­nh xÃ¡c trÃªn táº­p kiá»ƒm tra: {accuracy:.2f}')

# HÃ m dá»± Ä‘oÃ¡n kÃ¨m tÃªn ngÆ°á»i
def du_doan_ten(ten, input_data):
    input_df = pd.DataFrame([input_data], columns=X.columns)
    input_scaled = scaler.transform(input_df)
    prediction = model.predict(input_scaled)[0][0]

    print(f"\nğŸ‘‰ Dá»± Ä‘oÃ¡n cho {ten}:")
    print(f"   XÃ¡c suáº¥t máº¯c bá»‡nh tim: {prediction:.2f}")
    if prediction > 0.5:
        print("   â†’ CÃ³ nguy cÆ¡ bá»‹ bá»‡nh tim")
    else:
        print("   â†’ KhÃ´ng bá»‹ bá»‡nh tim")

# Dá»± Ä‘oÃ¡n cho tá»«ng ngÆ°á»i
du_doan_ten("Nguyá»…n VÄƒn A", (67,1,0,150,280,0,0,1000,1,3.6,0,2,2))
du_doan_ten("Tráº§n Thá»‹ B", (58,0,1,120,250,0,1,140,0,1.2,1,0,2))
du_doan_ten("Nguyá»…n VÄƒn C", (22,1,0,110,120,0,0,120,0,0.0,0,0,0))

